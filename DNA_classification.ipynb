{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEqkGUiiMIBE"
      },
      "source": [
        "## Library Imports\n",
        "All necessary libraries for data handling, modeling, training, and evaluation are imported here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T5t1oILd_jUs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6zi2SVRMSBM"
      },
      "source": [
        "## Load and Explore Data\n",
        "Load the training and test datasets, check dimensions, visualize class distribution, and preview a sample sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "DdjJqHy50Io3",
        "outputId": "96115542-8dd1-4df2-f1d5-705ff9d934a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xtr shape: (2000, 2)\n",
            "Ytr shape: (2000, 2)\n",
            "Xte shape: (1000, 2)\n",
            "\n",
            "Sample sequence from Xtr:\n",
            "0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_path = \"/content/df\"\n",
        "Xtr = pd.read_csv(os.path.join(data_path, \"Xtr.csv\"))\n",
        "Xte = pd.read_csv(os.path.join(data_path, \"Xte.csv\"))\n",
        "Ytr = pd.read_csv(os.path.join(data_path, \"Ytr.csv\"))\n",
        "Xtr_mat = pd.read_csv(os.path.join(data_path, \"Xtr_mat100.csv\"), sep='\\s+', header=None)\n",
        "Xte_mat = pd.read_csv(os.path.join(data_path, \"Xte_mat100.csv\"), sep='\\s+', header=None)\n",
        "\n",
        "# quick data check\n",
        "print(\"Xtr shape:\", Xtr.shape)\n",
        "print(\"Ytr shape:\", Ytr.shape)\n",
        "print(\"Xte shape:\", Xte.shape)\n",
        "\n",
        "print(\"\\nSample sequence from Xtr:\")\n",
        "print(Xtr.iloc[0, 0])\n",
        "\n",
        "# Check class distribution\n",
        "Ytr['Bound'].value_counts().plot(kind='bar', title='Class Distribution')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXcA0D7sCRUJ"
      },
      "source": [
        "## One-Hot Encoding of DNA Sequences\n",
        "Transform DNA sequences into one-hot encoded tensors and prepare cluster-based features for training and testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gds6chzK0NsY",
        "outputId": "61d26d87-8e0f-4062-b6e7-cb527bb18041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded and encoded.\n",
            "X_seq shape: (2000, 4, 101)\n",
            "X_test_seq shape: (1000, 4, 101)\n",
            "X_seq_tensor shape: torch.Size([2000, 4, 101])\n",
            "X_cluster_tensor shape: torch.Size([2000, 100])\n"
          ]
        }
      ],
      "source": [
        "def one_hot_encode_seq(seq, maxlen=101):\n",
        "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "    one_hot = np.zeros((4, maxlen), dtype=np.float32)\n",
        "    for i, char in enumerate(seq):\n",
        "        if char in mapping:\n",
        "            one_hot[mapping[char], i] = 1.0\n",
        "    return one_hot\n",
        "\n",
        "X_seq = np.stack([one_hot_encode_seq(seq) for seq in Xtr[\"seq\"]])\n",
        "X_test_seq = np.stack([one_hot_encode_seq(seq) for seq in Xte[\"seq\"]])\n",
        "\n",
        "X_seq_tensor = torch.tensor(X_seq, dtype=torch.float32)\n",
        "X_test_seq_tensor = torch.tensor(X_test_seq, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(Ytr[\"Bound\"].values, dtype=torch.float32)\n",
        "\n",
        "X_cluster_tensor = torch.tensor(Xtr_mat.values, dtype=torch.float32)\n",
        "X_test_cluster_tensor = torch.tensor(Xte_mat.values, dtype=torch.float32)\n",
        "\n",
        "print(\"Data loaded and encoded.\")\n",
        "print(\"X_seq shape:\", X_seq.shape)\n",
        "print(\"X_test_seq shape:\", X_test_seq.shape)\n",
        "print(f\"X_seq_tensor shape: {X_seq_tensor.shape}\")\n",
        "print(f\"X_cluster_tensor shape: {X_cluster_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V9pUAgMC4hI"
      },
      "source": [
        "## Model Architecture Definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_SxgK-67Cqff"
      },
      "outputs": [],
      "source": [
        "# Define models\n",
        "class CNNKMeansFusion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(4, 128, kernel_size=9, padding=4),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=15, padding=7),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(256 + 50, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x_seq, x_clust):\n",
        "        x_cnn = self.cnn(x_seq)\n",
        "        x_concat = torch.cat([x_cnn, x_clust], dim=1)\n",
        "        return self.mlp(x_concat)\n",
        "\n",
        "class CNNOnlyV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv1d(4, 128, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(128, 256, kernel_size=11, padding=5),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv1d(256, 256, kernel_size=15, padding=7),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Instantiate models\n",
        "model1 = CNNKMeansFusion()\n",
        "model2 = CNNOnlyV2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTeOtOZgDVBw"
      },
      "source": [
        "## Data Preprocessing & Custom Dataset Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yvboFwPR02zl"
      },
      "outputs": [],
      "source": [
        "# truncate first\n",
        "X_cluster_tensor = X_cluster_tensor[:, :50]\n",
        "X_test_cluster_tensor = X_test_cluster_tensor[:, :50]\n",
        "\n",
        "# then normalize\n",
        "scaler = StandardScaler()\n",
        "X_cluster = scaler.fit_transform(X_cluster_tensor)\n",
        "X_test_cluster = scaler.transform(X_test_cluster_tensor)\n",
        "\n",
        "X_cluster_tensor = torch.tensor(X_cluster, dtype=torch.float32)\n",
        "X_test_cluster_tensor = torch.tensor(X_test_cluster, dtype=torch.float32)\n",
        "\n",
        "# train/validation split\n",
        "X_seq_train, X_seq_val, X_clust_train, X_clust_val, y_train, y_val = train_test_split(\n",
        "    X_seq_tensor, X_cluster_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "## Custom dataset for dual-input (sequence + cluster) models\n",
        "class DualInputDataset(Dataset):\n",
        "    def __init__(self, seq_tensor, clust_tensor, labels):\n",
        "        self.seq = seq_tensor\n",
        "        self.clust = clust_tensor\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.seq[idx], self.clust[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = DualInputDataset(X_seq_train, X_clust_train, y_train)\n",
        "val_dataset = DualInputDataset(X_seq_val, X_clust_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A18LgTIrDoUj"
      },
      "source": [
        "## Model Training: Loss, Accuracy & Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJouezp31Nm_",
        "outputId": "0e3e98b6-867d-4e50-992b-bd9efdd278e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training CNN+KMeans model...\n",
            "[cnn_kmeans] Epoch 01 - Loss: 0.7131 - Val Accuracy: 0.4775 - Best: 0.4775\n",
            "[cnn_kmeans] Epoch 02 - Loss: 0.6503 - Val Accuracy: 0.6650 - Best: 0.6650\n",
            "[cnn_kmeans] Epoch 03 - Loss: 0.5554 - Val Accuracy: 0.6975 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 04 - Loss: 0.4744 - Val Accuracy: 0.6700 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 05 - Loss: 0.4069 - Val Accuracy: 0.7075 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 06 - Loss: 0.3123 - Val Accuracy: 0.7000 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 07 - Loss: 0.1817 - Val Accuracy: 0.6350 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 08 - Loss: 0.1448 - Val Accuracy: 0.6725 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 09 - Loss: 0.1431 - Val Accuracy: 0.6900 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 10 - Loss: 0.2202 - Val Accuracy: 0.6800 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 11 - Loss: 0.1267 - Val Accuracy: 0.6975 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 12 - Loss: 0.0718 - Val Accuracy: 0.6950 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 13 - Loss: 0.0827 - Val Accuracy: 0.6675 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 14 - Loss: 0.2463 - Val Accuracy: 0.7000 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 15 - Loss: 0.1365 - Val Accuracy: 0.6975 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 16 - Loss: 0.1248 - Val Accuracy: 0.7175 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 17 - Loss: 0.0928 - Val Accuracy: 0.7125 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 18 - Loss: 0.0884 - Val Accuracy: 0.7050 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 19 - Loss: 0.0843 - Val Accuracy: 0.7075 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 20 - Loss: 0.0630 - Val Accuracy: 0.7150 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 21 - Loss: 0.0898 - Val Accuracy: 0.7050 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 22 - Loss: 0.1563 - Val Accuracy: 0.6575 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 23 - Loss: 0.1917 - Val Accuracy: 0.6975 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 24 - Loss: 0.1043 - Val Accuracy: 0.6900 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 25 - Loss: 0.0891 - Val Accuracy: 0.6925 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 26 - Loss: 0.1058 - Val Accuracy: 0.6750 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 27 - Loss: 0.0750 - Val Accuracy: 0.6650 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 28 - Loss: 0.1186 - Val Accuracy: 0.6850 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 29 - Loss: 0.1564 - Val Accuracy: 0.7000 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 30 - Loss: 0.1388 - Val Accuracy: 0.6925 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 31 - Loss: 0.0992 - Val Accuracy: 0.6975 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 32 - Loss: 0.1022 - Val Accuracy: 0.6875 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 33 - Loss: 0.0676 - Val Accuracy: 0.7075 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 34 - Loss: 0.0824 - Val Accuracy: 0.6875 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 35 - Loss: 0.0670 - Val Accuracy: 0.7000 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 36 - Loss: 0.0703 - Val Accuracy: 0.7075 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 37 - Loss: 0.0824 - Val Accuracy: 0.7075 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 38 - Loss: 0.0714 - Val Accuracy: 0.6750 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 39 - Loss: 0.0718 - Val Accuracy: 0.7025 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 40 - Loss: 0.1303 - Val Accuracy: 0.6700 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 41 - Loss: 0.1447 - Val Accuracy: 0.6625 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 42 - Loss: 0.1025 - Val Accuracy: 0.6675 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 43 - Loss: 0.0730 - Val Accuracy: 0.6350 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 44 - Loss: 0.0979 - Val Accuracy: 0.6825 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 45 - Loss: 0.0630 - Val Accuracy: 0.6925 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 46 - Loss: 0.0899 - Val Accuracy: 0.6925 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 47 - Loss: 0.0857 - Val Accuracy: 0.7100 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 48 - Loss: 0.0781 - Val Accuracy: 0.6500 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 49 - Loss: 0.0720 - Val Accuracy: 0.6900 - Best: 0.7175\n",
            "[cnn_kmeans] Epoch 50 - Loss: 0.0656 - Val Accuracy: 0.6950 - Best: 0.7175\n",
            "\n",
            "Training CNNOnly model...\n",
            "[cnn_only] Epoch 01 - Loss: 0.7264 - Val Accuracy: 0.5225 - Best: 0.5225\n",
            "[cnn_only] Epoch 02 - Loss: 0.6979 - Val Accuracy: 0.5400 - Best: 0.5400\n",
            "[cnn_only] Epoch 03 - Loss: 0.6903 - Val Accuracy: 0.5025 - Best: 0.5400\n",
            "[cnn_only] Epoch 04 - Loss: 0.6406 - Val Accuracy: 0.6625 - Best: 0.6625\n",
            "[cnn_only] Epoch 05 - Loss: 0.6198 - Val Accuracy: 0.6875 - Best: 0.6875\n",
            "[cnn_only] Epoch 06 - Loss: 0.5877 - Val Accuracy: 0.6325 - Best: 0.6875\n",
            "[cnn_only] Epoch 07 - Loss: 0.5646 - Val Accuracy: 0.7100 - Best: 0.7100\n",
            "[cnn_only] Epoch 08 - Loss: 0.5474 - Val Accuracy: 0.7125 - Best: 0.7125\n",
            "[cnn_only] Epoch 09 - Loss: 0.5348 - Val Accuracy: 0.6675 - Best: 0.7125\n",
            "[cnn_only] Epoch 10 - Loss: 0.4924 - Val Accuracy: 0.6875 - Best: 0.7125\n",
            "[cnn_only] Epoch 11 - Loss: 0.4647 - Val Accuracy: 0.6550 - Best: 0.7125\n",
            "[cnn_only] Epoch 12 - Loss: 0.4009 - Val Accuracy: 0.6825 - Best: 0.7125\n",
            "[cnn_only] Epoch 13 - Loss: 0.4225 - Val Accuracy: 0.7025 - Best: 0.7125\n",
            "[cnn_only] Epoch 14 - Loss: 0.3894 - Val Accuracy: 0.6950 - Best: 0.7125\n",
            "[cnn_only] Epoch 15 - Loss: 0.3471 - Val Accuracy: 0.7225 - Best: 0.7225\n",
            "[cnn_only] Epoch 16 - Loss: 0.3508 - Val Accuracy: 0.6850 - Best: 0.7225\n",
            "[cnn_only] Epoch 17 - Loss: 0.3274 - Val Accuracy: 0.6875 - Best: 0.7225\n",
            "[cnn_only] Epoch 18 - Loss: 0.3268 - Val Accuracy: 0.6925 - Best: 0.7225\n",
            "[cnn_only] Epoch 19 - Loss: 0.3094 - Val Accuracy: 0.6900 - Best: 0.7225\n",
            "[cnn_only] Epoch 20 - Loss: 0.3056 - Val Accuracy: 0.7050 - Best: 0.7225\n",
            "[cnn_only] Epoch 21 - Loss: 0.2999 - Val Accuracy: 0.7075 - Best: 0.7225\n",
            "[cnn_only] Epoch 22 - Loss: 0.3138 - Val Accuracy: 0.6525 - Best: 0.7225\n",
            "[cnn_only] Epoch 23 - Loss: 0.2826 - Val Accuracy: 0.6775 - Best: 0.7225\n",
            "[cnn_only] Epoch 24 - Loss: 0.3008 - Val Accuracy: 0.6525 - Best: 0.7225\n",
            "[cnn_only] Epoch 25 - Loss: 0.3127 - Val Accuracy: 0.7025 - Best: 0.7225\n",
            "[cnn_only] Epoch 26 - Loss: 0.2775 - Val Accuracy: 0.6475 - Best: 0.7225\n",
            "[cnn_only] Epoch 27 - Loss: 0.3128 - Val Accuracy: 0.6675 - Best: 0.7225\n",
            "[cnn_only] Epoch 28 - Loss: 0.3014 - Val Accuracy: 0.6725 - Best: 0.7225\n",
            "[cnn_only] Epoch 29 - Loss: 0.3084 - Val Accuracy: 0.6900 - Best: 0.7225\n",
            "[cnn_only] Epoch 30 - Loss: 0.2915 - Val Accuracy: 0.6975 - Best: 0.7225\n",
            "[cnn_only] Epoch 31 - Loss: 0.2996 - Val Accuracy: 0.6725 - Best: 0.7225\n",
            "[cnn_only] Epoch 32 - Loss: 0.2984 - Val Accuracy: 0.6650 - Best: 0.7225\n",
            "[cnn_only] Epoch 33 - Loss: 0.3230 - Val Accuracy: 0.7200 - Best: 0.7225\n",
            "[cnn_only] Epoch 34 - Loss: 0.3263 - Val Accuracy: 0.6850 - Best: 0.7225\n",
            "[cnn_only] Epoch 35 - Loss: 0.3268 - Val Accuracy: 0.6825 - Best: 0.7225\n",
            "[cnn_only] Epoch 36 - Loss: 0.3388 - Val Accuracy: 0.6650 - Best: 0.7225\n",
            "[cnn_only] Epoch 37 - Loss: 0.3026 - Val Accuracy: 0.6675 - Best: 0.7225\n",
            "[cnn_only] Epoch 38 - Loss: 0.3112 - Val Accuracy: 0.6975 - Best: 0.7225\n",
            "[cnn_only] Epoch 39 - Loss: 0.2811 - Val Accuracy: 0.6725 - Best: 0.7225\n",
            "[cnn_only] Epoch 40 - Loss: 0.2793 - Val Accuracy: 0.7150 - Best: 0.7225\n",
            "[cnn_only] Epoch 41 - Loss: 0.2874 - Val Accuracy: 0.6875 - Best: 0.7225\n",
            "[cnn_only] Epoch 42 - Loss: 0.2757 - Val Accuracy: 0.6825 - Best: 0.7225\n",
            "[cnn_only] Epoch 43 - Loss: 0.2945 - Val Accuracy: 0.7075 - Best: 0.7225\n",
            "[cnn_only] Epoch 44 - Loss: 0.2757 - Val Accuracy: 0.7025 - Best: 0.7225\n",
            "[cnn_only] Epoch 45 - Loss: 0.2811 - Val Accuracy: 0.7100 - Best: 0.7225\n",
            "[cnn_only] Epoch 46 - Loss: 0.2684 - Val Accuracy: 0.7200 - Best: 0.7225\n",
            "[cnn_only] Epoch 47 - Loss: 0.2685 - Val Accuracy: 0.7025 - Best: 0.7225\n",
            "[cnn_only] Epoch 48 - Loss: 0.3002 - Val Accuracy: 0.6975 - Best: 0.7225\n",
            "[cnn_only] Epoch 49 - Loss: 0.2714 - Val Accuracy: 0.6975 - Best: 0.7225\n",
            "[cnn_only] Epoch 50 - Loss: 0.2764 - Val Accuracy: 0.6975 - Best: 0.7225\n"
          ]
        }
      ],
      "source": [
        "# Define loss and accuracy\n",
        "def compute_accuracy(preds, labels):\n",
        "    preds = (preds >= 0.5).float()\n",
        "    correct = (preds == labels).float().sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "# Training loop function\n",
        "def train_model(model, optimizer, train_loader, val_loader, mode=\"cnn_kmeans\", epochs=50):\n",
        "    loss_fn = nn.BCELoss()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xb, xc, yb in train_loader:\n",
        "            if mode == \"cnn_only\":\n",
        "                preds = model(xb).squeeze()\n",
        "            elif mode == \"mlp\":\n",
        "                preds = model(xc).squeeze()\n",
        "            else:  # cnn_kmeans\n",
        "                preds = model(xb, xc).squeeze()\n",
        "\n",
        "            loss = loss_fn(preds, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_targets = []\n",
        "        with torch.no_grad():\n",
        "            for xb, xc, yb in val_loader:\n",
        "                if mode == \"cnn_only\":\n",
        "                    preds = model(xb).squeeze()\n",
        "                elif mode == \"mlp\":\n",
        "                    preds = model(xc).squeeze()\n",
        "                else:\n",
        "                    preds = model(xb, xc).squeeze()\n",
        "                val_preds.append(preds)\n",
        "                val_targets.append(yb)\n",
        "\n",
        "        val_preds = torch.cat(val_preds)\n",
        "        val_targets = torch.cat(val_targets)\n",
        "        val_acc = ((val_preds >= 0.5).float() == val_targets).float().mean().item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Print output for each epoch\n",
        "        print(f\"[{mode}] Epoch {epoch+1:02d} - Loss: {avg_loss:.4f} - Val Accuracy: {val_acc:.4f} - Best: {max(val_acc, best_acc):.4f}\", flush=True)\n",
        "\n",
        "        best_acc = max(best_acc, val_acc)\n",
        "\n",
        "# Define optimizers\n",
        "opt1 = torch.optim.Adam(model1.parameters(), lr=0.002)  # CNN+KMeans\n",
        "opt2 = torch.optim.Adam(model2.parameters(), lr=0.003)  # CNNOnly\n",
        "\n",
        "# Train both models\n",
        "print(\"Training CNN+KMeans model...\", flush=True)\n",
        "train_model(model1, opt1, train_loader, val_loader, mode=\"cnn_kmeans\", epochs=50)\n",
        "\n",
        "print(\"\\nTraining CNNOnly model...\", flush=True)\n",
        "train_model(model2, opt2, train_loader, val_loader, mode=\"cnn_only\", epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErEPp0x6FcMn"
      },
      "source": [
        "## Generate final predictions and create submission file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHqs6oVcGiUO"
      },
      "source": [
        "This section combines the predictions from both trained models using a weighted average, then saves the final results in the Kaggle submission format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBNJ0TSK6YIQ",
        "outputId": "c0a5b245-2400-47be-c196-a15f76cba528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file 'Submission.csv' generated successfully.\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions from both models\n",
        "with torch.no_grad():\n",
        "    preds1 = model1(X_test_seq_tensor, X_test_cluster_tensor).squeeze()\n",
        "    preds2 = model2(X_test_seq_tensor).squeeze()\n",
        "\n",
        "    alpha = 0.715\n",
        "    final_probs = (alpha * preds1 + (1 - alpha) * preds2).cpu().numpy()\n",
        "    final_preds = (final_probs >= 0.5).astype(int)\n",
        "\n",
        "# save the predictions into a CSV file\n",
        "submission_name = \"Submission.csv\"\n",
        "with open(submission_name, \"w\") as f:\n",
        "    f.write(\"Id,Bound\\n\")\n",
        "    for i, p in enumerate(final_preds):\n",
        "        f.write(f\"{i},{p}\\n\")\n",
        "\n",
        "print(f\"Submission file '{submission_name}' generated successfully.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
