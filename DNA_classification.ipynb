{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEqkGUiiMIBE"
      },
      "source": [
        "## Essentials lib import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T5t1oILd_jUs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6zi2SVRMSBM"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yWlixB5pMcR5"
      },
      "outputs": [],
      "source": [
        "# Load CSV files ---\n",
        "data_path = \"/content/data\"  # adapte si n√©cessaire\n",
        "Xtr = pd.read_csv(os.path.join(data_path, \"Xtr.csv\"))\n",
        "Xte = pd.read_csv(os.path.join(data_path, \"Xte.csv\"))\n",
        "Ytr = pd.read_csv(os.path.join(data_path, \"Ytr.csv\"))\n",
        "Xtr_mat = pd.read_csv(os.path.join(data_path, \"Xtr_mat100.csv\"), sep='\\s+', header=None)\n",
        "Xte_mat = pd.read_csv(os.path.join(data_path, \"Xte_mat100.csv\"), sep='\\s+', header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Pv8OiX-u9b"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "titBnK8Q-xiH",
        "outputId": "619a6994-c885-4f02-d566-95f5689cbd8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xtr shape: (2000, 2)\n",
            "Ytr shape: (2000, 2)\n",
            "Xte shape: (1000, 2)\n",
            "\n",
            "Sample sequence from Xtr:\n",
            "0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# [3] Quick data check\n",
        "print(\"Xtr shape:\", Xtr.shape)\n",
        "print(\"Ytr shape:\", Ytr.shape)\n",
        "print(\"Xte shape:\", Xte.shape)\n",
        "\n",
        "print(\"\\nSample sequence from Xtr:\")\n",
        "print(Xtr.iloc[0, 0])\n",
        "\n",
        "# Check class distribution\n",
        "Ytr['Bound'].value_counts().plot(kind='bar', title='Class Distribution')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64_RTYHVMn2r"
      },
      "source": [
        "### Prepare PyTorch tensors from precomputed features (fixed for space-separated data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMwoD5dJ_55I",
        "outputId": "4faca2af-b29e-42d1-cd93-1406356886e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-6134d1b622ba>:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  Xtr_mat = pd.read_csv(os.path.join(data_path, \"Xtr_mat100.csv\"), delim_whitespace=True, header=None, dtype=np.float32)\n",
            "<ipython-input-8-6134d1b622ba>:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  Xte_mat = pd.read_csv(os.path.join(data_path, \"Xte_mat100.csv\"), delim_whitespace=True, header=None, dtype=np.float32)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 1600, Validation samples: 400\n"
          ]
        }
      ],
      "source": [
        "# Load as space-delimited (not comma)\n",
        "Xtr_mat = pd.read_csv(os.path.join(data_path, \"Xtr_mat100.csv\"), delim_whitespace=True, header=None, dtype=np.float32)\n",
        "Xte_mat = pd.read_csv(os.path.join(data_path, \"Xte_mat100.csv\"), delim_whitespace=True, header=None, dtype=np.float32)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X = torch.tensor(Xtr_mat.values, dtype=torch.float32)\n",
        "y = torch.tensor(Ytr[\"Bound\"].values, dtype=torch.float32)\n",
        "\n",
        "# Split into train/val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Wrap into Datasets and Loaders\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMkxNor0Mmeg"
      },
      "source": [
        "### Data Preprocessing & Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GMU4zZf0HAmu"
      },
      "outputs": [],
      "source": [
        "def extract_kmers(seq, k=10):\n",
        "    return [seq[i:i+k] for i in range(len(seq) - k + 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YPafDrZOHE89"
      },
      "outputs": [],
      "source": [
        "def kmer_to_onehot(kmer):\n",
        "    mapping = {'A': [1, 0, 0, 0],\n",
        "               'C': [0, 1, 0, 0],\n",
        "               'G': [0, 0, 1, 0],\n",
        "               'T': [0, 0, 0, 1]}\n",
        "    return np.array([mapping[base] for base in kmer]).flatten()\n",
        "# Convert full sequences to one-hot tensors (shape: N x 100 x 4)\n",
        "def full_sequence_to_onehot(seq):\n",
        "    mapping = {'A': [1, 0, 0, 0],\n",
        "               'C': [0, 1, 0, 0],\n",
        "               'G': [0, 0, 1, 0],\n",
        "               'T': [0, 0, 0, 1]}\n",
        "    return np.array([mapping[base] for base in seq])\n",
        "\n",
        "X_seq = np.array([full_sequence_to_onehot(seq) for seq in Xtr[\"seq\"]])\n",
        "X_test_seq = np.array([full_sequence_to_onehot(seq) for seq in Xte[\"seq\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbbI8fd5HGMv",
        "outputId": "1036ca10-ab03-4599-cf24-8e84e84b60c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:01<00:00, 1024.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total k-mers: (184000, 40)\n"
          ]
        }
      ],
      "source": [
        "def all_kmer_onehots(sequences, k=10):\n",
        "    all_kmers = []\n",
        "    for seq in tqdm(sequences):\n",
        "        kmers = extract_kmers(seq, k)\n",
        "        all_kmers.extend([kmer_to_onehot(k) for k in kmers])\n",
        "    return np.array(all_kmers)\n",
        "\n",
        "all_kmer_vectors = all_kmer_onehots(Xtr[\"seq\"], k=10)\n",
        "print(\"Total k-mers:\", all_kmer_vectors.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "fJt68AGLHSki",
        "outputId": "5825d03e-db58-4922-d175-e26078236388"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=50, n_init=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KMeans</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=50, n_init=10, random_state=42)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "KMeans(n_clusters=50, n_init=10, random_state=42)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "n_clusters = 50\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "kmeans.fit(all_kmer_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6OasbOoOApD"
      },
      "source": [
        "###  Clustering-based Feature Extraction with k-mers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pd2ksmXHcTR",
        "outputId": "4f341545-85c7-4779-ac9f-176475fc8deb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2000/2000 [00:02<00:00, 702.57it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:01<00:00, 665.28it/s]\n"
          ]
        }
      ],
      "source": [
        "def sequence_to_cluster_vector(seq, k=10):\n",
        "    kmers = extract_kmers(seq, k)\n",
        "    vectors = [kmer_to_onehot(k) for k in kmers]\n",
        "    cluster_ids = kmeans.predict(vectors)\n",
        "    cluster_onehots = np.zeros((len(cluster_ids), n_clusters), dtype=np.float32)\n",
        "    for i, cluster_id in enumerate(cluster_ids):\n",
        "        cluster_onehots[i, cluster_id] = 1\n",
        "    return cluster_onehots.mean(axis=0)\n",
        "\n",
        "X_cluster = np.array([sequence_to_cluster_vector(seq) for seq in tqdm(Xtr[\"seq\"])])\n",
        "X_test_cluster = np.array([sequence_to_cluster_vector(seq) for seq in tqdm(Xte[\"seq\"])])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn10aQPJOf8p"
      },
      "source": [
        "### Preprocessing: Normalization and Tensor Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R16Wmjf3OiSn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_cluster = scaler.fit_transform(X_cluster)\n",
        "X_test_cluster = scaler.transform(X_test_cluster)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_seq_tensor = torch.tensor(X_seq).permute(0, 2, 1)\n",
        "X_cluster_tensor = torch.tensor(X_cluster, dtype=torch.float32)\n",
        "X_test_seq_tensor = torch.tensor(X_test_seq).permute(0, 2, 1)\n",
        "X_test_cluster_tensor = torch.tensor(X_test_cluster, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(Ytr[\"Bound\"].values, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okY2aAB-OmTN"
      },
      "source": [
        "### Dataset & Dataloaders: Dual Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tZYTDilcI_LA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "X_seq_train, X_seq_val, X_clust_train, X_clust_val, y_train, y_val = train_test_split(\n",
        "    X_seq_tensor, X_cluster_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "class DualInputDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, seq_tensor, clust_tensor, labels):\n",
        "        self.seq = seq_tensor\n",
        "        self.clust = clust_tensor\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.seq[idx], self.clust[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DualInputDataset(X_seq_train, X_clust_train, y_train)\n",
        "val_dataset = DualInputDataset(X_seq_val, X_clust_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMuHLRgXDr7f"
      },
      "source": [
        "## SUBMISSION 7 - Ensemble CNN+KMeans + CNN-only (Avg Fusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4qunSKdNRbK",
        "outputId": "324f87f5-8a45-46d6-d869-cdd17a74e3f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All data loaded and encoded.\n",
            "Train sequences shape: torch.Size([2000, 4, 101])\n",
            "Test sequences shape:  torch.Size([1000, 4, 101])\n"
          ]
        }
      ],
      "source": [
        "# One-hot encoding function\n",
        "def one_hot_encode_seq(seq, maxlen=101):\n",
        "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "    one_hot = np.zeros((4, maxlen), dtype=np.float32)\n",
        "    for i, char in enumerate(seq):\n",
        "        if char in mapping:\n",
        "            one_hot[mapping[char], i] = 1.0\n",
        "    return one_hot\n",
        "\n",
        "# Apply one-hot to all sequences\n",
        "X_seq = np.stack([one_hot_encode_seq(seq) for seq in Xtr[\"seq\"]])\n",
        "X_test_seq = np.stack([one_hot_encode_seq(seq) for seq in Xte[\"seq\"]])\n",
        "\n",
        "# Convert all to PyTorch tensors\n",
        "X_seq_tensor = torch.tensor(X_seq, dtype=torch.float32)\n",
        "X_test_seq_tensor = torch.tensor(X_test_seq, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(Ytr[\"Bound\"].values, dtype=torch.float32)\n",
        "\n",
        "X_cluster_tensor = torch.tensor(Xtr_mat.values, dtype=torch.float32)\n",
        "X_test_cluster_tensor = torch.tensor(Xte_mat.values, dtype=torch.float32)\n",
        "\n",
        "print(\"All data loaded and encoded.\")\n",
        "print(f\"Train sequences shape: {X_seq_tensor.shape}\")\n",
        "print(f\"Test sequences shape:  {X_test_seq_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eRs_oXHMDx19"
      },
      "outputs": [],
      "source": [
        "# Normalize KMeans features ---\n",
        "scaler = StandardScaler()\n",
        "X_cluster = scaler.fit_transform(X_cluster)\n",
        "X_test_cluster = scaler.transform(X_test_cluster)\n",
        "\n",
        "X_cluster_tensor = torch.tensor(X_cluster, dtype=torch.float32)\n",
        "X_test_cluster_tensor = torch.tensor(X_test_cluster, dtype=torch.float32)\n",
        "\n",
        "# Prepare train/val split\n",
        "X_seq_train, X_seq_val, X_clust_train, X_clust_val, y_train, y_val = train_test_split(\n",
        "    X_seq_tensor, X_cluster_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dataset for CNN+KMeans\n",
        "class DualInputDataset(Dataset):\n",
        "    def __init__(self, seq_tensor, clust_tensor, labels):\n",
        "        self.seq = seq_tensor\n",
        "        self.clust = clust_tensor\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.seq[idx], self.clust[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DualInputDataset(X_seq_train, X_clust_train, y_train)\n",
        "val_dataset = DualInputDataset(X_seq_val, X_clust_val, y_val)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# CNN+KMeans model (pre-trained)\n",
        "class CNNKMeansFusion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(4, 128, kernel_size=9, padding=4),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=15, padding=7),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(256 + 50, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x_seq, x_clust):\n",
        "        x_cnn = self.cnn(x_seq)\n",
        "        x_concat = torch.cat([x_cnn, x_clust], dim=1)\n",
        "        return self.mlp(x_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5b8QElTHBnA",
        "outputId": "aeb6ffbd-6c9b-4783-bc23-da96cdb1367c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 - Loss: 0.7006 - Val Accuracy: 0.6175\n",
            "Epoch 02 - Loss: 0.6762 - Val Accuracy: 0.6150\n",
            "Epoch 03 - Loss: 0.5769 - Val Accuracy: 0.6950\n",
            "Epoch 04 - Loss: 0.4871 - Val Accuracy: 0.6850\n",
            "Epoch 05 - Loss: 0.3986 - Val Accuracy: 0.6875\n",
            "Epoch 06 - Loss: 0.2572 - Val Accuracy: 0.7050\n",
            "Epoch 07 - Loss: 0.1765 - Val Accuracy: 0.7025\n",
            "Epoch 08 - Loss: 0.0798 - Val Accuracy: 0.6950\n",
            "Epoch 09 - Loss: 0.0295 - Val Accuracy: 0.6625\n",
            "Epoch 10 - Loss: 0.0872 - Val Accuracy: 0.6925\n",
            "Epoch 11 - Loss: 0.0249 - Val Accuracy: 0.6825\n",
            "Epoch 12 - Loss: 0.0105 - Val Accuracy: 0.7000\n",
            "Epoch 13 - Loss: 0.0074 - Val Accuracy: 0.6975\n",
            "Epoch 14 - Loss: 0.0026 - Val Accuracy: 0.7025\n",
            "Epoch 15 - Loss: 0.0010 - Val Accuracy: 0.6950\n",
            "Epoch 16 - Loss: 0.0008 - Val Accuracy: 0.7000\n",
            "Epoch 17 - Loss: 0.0006 - Val Accuracy: 0.7025\n",
            "Epoch 18 - Loss: 0.0006 - Val Accuracy: 0.7025\n",
            "Epoch 19 - Loss: 0.0005 - Val Accuracy: 0.6925\n",
            "Epoch 20 - Loss: 0.0004 - Val Accuracy: 0.6950\n"
          ]
        }
      ],
      "source": [
        "# CNN-only model (new training)\n",
        "class CNNOnly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(4, 128, kernel_size=7, padding=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=11, padding=5),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model2 = CNNOnly()\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.003)\n",
        "# Train CNN-only model with validation accuracy\n",
        "def compute_accuracy(preds, labels):\n",
        "    preds = (preds >= 0.5).float()\n",
        "    correct = (preds == labels).float().sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "for epoch in range(20):\n",
        "    model2.train()\n",
        "    total_loss = 0\n",
        "    for xb, _, yb in train_loader:\n",
        "        preds = model2(xb).squeeze()\n",
        "        loss = loss_fn(preds, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # --- Validation ---\n",
        "    model2.eval()\n",
        "    val_preds = []\n",
        "    val_targets = []\n",
        "    with torch.no_grad():\n",
        "        for xb, _, yb in val_loader:\n",
        "            preds = model2(xb).squeeze()\n",
        "            val_preds.append(preds)\n",
        "            val_targets.append(yb)\n",
        "    val_preds = torch.cat(val_preds)\n",
        "    val_targets = torch.cat(val_targets)\n",
        "    val_acc = compute_accuracy(val_preds, val_targets)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d} - Loss: {total_loss/len(train_loader):.4f} - Val Accuracy: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "XfEZS2_1Fwrz"
      },
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    preds1 = model1(X_test_seq_tensor, X_test_cluster_tensor).squeeze()\n",
        "    preds2 = model2(X_test_seq_tensor).squeeze()\n",
        "\n",
        "    avg_preds = ((preds1 + preds2) / 2).cpu().numpy()\n",
        "    final_preds = (avg_preds >= 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOvmkDqAGL2O",
        "outputId": "843809d3-c4d4-432d-bf23-5581ea621938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble submission.csv ready\n"
          ]
        }
      ],
      "source": [
        "# Create submission.csv\n",
        "with open(\"submission.csv\", \"w\") as f:\n",
        "    f.write(\"Id,Bound\\n\")\n",
        "    for i, p in enumerate(final_preds):\n",
        "        f.write(f\"{i},{p}\\n\")\n",
        "\n",
        "print(\"Ensemble submission.csv ready\")\n",
        "# Submit (when ready)\n",
        "!kaggle competitions submit -c dna-intro-to-neural-nets-aims-rwanda-2025 -f submission.csv -m \"Submission 11 - Ensemble (CNN+KMeans + CNN-only avg)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjrrzNV9YVJI"
      },
      "source": [
        "## Submission 11\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stMLsNWpaElm",
        "outputId": "91d3cd6e-f13a-439b-b04b-4afee745dacc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Training CNN+KMeans model...\n",
            "[cnn_kmeans] Epoch 001 - Loss: 0.7181 - Val Accuracy: 0.6125 - Best: 0.6125\n",
            "[cnn_kmeans] Epoch 002 - Loss: 0.6745 - Val Accuracy: 0.6800 - Best: 0.6800\n",
            "[cnn_kmeans] Epoch 003 - Loss: 0.5962 - Val Accuracy: 0.6450 - Best: 0.6800\n",
            "[cnn_kmeans] Epoch 004 - Loss: 0.5336 - Val Accuracy: 0.7250 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 005 - Loss: 0.4237 - Val Accuracy: 0.6575 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 006 - Loss: 0.3424 - Val Accuracy: 0.6650 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 007 - Loss: 0.2832 - Val Accuracy: 0.6850 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 008 - Loss: 0.2030 - Val Accuracy: 0.6825 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 009 - Loss: 0.1572 - Val Accuracy: 0.6875 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 010 - Loss: 0.1164 - Val Accuracy: 0.6750 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 011 - Loss: 0.0929 - Val Accuracy: 0.6500 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 012 - Loss: 0.1238 - Val Accuracy: 0.6725 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 013 - Loss: 0.0826 - Val Accuracy: 0.6750 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 014 - Loss: 0.0674 - Val Accuracy: 0.6600 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 015 - Loss: 0.1076 - Val Accuracy: 0.6725 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 016 - Loss: 0.0831 - Val Accuracy: 0.6575 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 017 - Loss: 0.0751 - Val Accuracy: 0.6625 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 018 - Loss: 0.0553 - Val Accuracy: 0.6775 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 019 - Loss: 0.0733 - Val Accuracy: 0.6550 - Best: 0.7250\n",
            "[cnn_kmeans] Epoch 020 - Loss: 0.0579 - Val Accuracy: 0.6475 - Best: 0.7250\n",
            "\n",
            "üîß Training CNNOnly model...\n",
            "[cnn_only] Epoch 001 - Loss: 0.6938 - Val Accuracy: 0.4775 - Best: 0.4775\n",
            "[cnn_only] Epoch 002 - Loss: 0.6075 - Val Accuracy: 0.7100 - Best: 0.7100\n",
            "[cnn_only] Epoch 003 - Loss: 0.4688 - Val Accuracy: 0.7050 - Best: 0.7100\n",
            "[cnn_only] Epoch 004 - Loss: 0.3271 - Val Accuracy: 0.6600 - Best: 0.7100\n",
            "[cnn_only] Epoch 005 - Loss: 0.2271 - Val Accuracy: 0.6800 - Best: 0.7100\n",
            "[cnn_only] Epoch 006 - Loss: 0.0929 - Val Accuracy: 0.6925 - Best: 0.7100\n",
            "[cnn_only] Epoch 007 - Loss: 0.0521 - Val Accuracy: 0.6800 - Best: 0.7100\n",
            "[cnn_only] Epoch 008 - Loss: 0.0402 - Val Accuracy: 0.7075 - Best: 0.7100\n",
            "[cnn_only] Epoch 009 - Loss: 0.0856 - Val Accuracy: 0.6800 - Best: 0.7100\n",
            "[cnn_only] Epoch 010 - Loss: 0.0219 - Val Accuracy: 0.7000 - Best: 0.7100\n",
            "[cnn_only] Epoch 011 - Loss: 0.0157 - Val Accuracy: 0.7050 - Best: 0.7100\n",
            "[cnn_only] Epoch 012 - Loss: 0.0263 - Val Accuracy: 0.7000 - Best: 0.7100\n",
            "[cnn_only] Epoch 013 - Loss: 0.0068 - Val Accuracy: 0.7000 - Best: 0.7100\n",
            "[cnn_only] Epoch 014 - Loss: 0.0013 - Val Accuracy: 0.7050 - Best: 0.7100\n",
            "[cnn_only] Epoch 015 - Loss: 0.0012 - Val Accuracy: 0.7050 - Best: 0.7100\n",
            "[cnn_only] Epoch 016 - Loss: 0.0007 - Val Accuracy: 0.7075 - Best: 0.7100\n",
            "[cnn_only] Epoch 017 - Loss: 0.0004 - Val Accuracy: 0.7125 - Best: 0.7125\n",
            "[cnn_only] Epoch 018 - Loss: 0.0004 - Val Accuracy: 0.7100 - Best: 0.7125\n",
            "[cnn_only] Epoch 019 - Loss: 0.0003 - Val Accuracy: 0.7100 - Best: 0.7125\n",
            "[cnn_only] Epoch 020 - Loss: 0.0002 - Val Accuracy: 0.7025 - Best: 0.7125\n",
            "\n",
            "üîß Training MLPOnClusters model...\n",
            "[mlp] Epoch 001 - Loss: 0.6924 - Val Accuracy: 0.5800 - Best: 0.5800\n",
            "[mlp] Epoch 002 - Loss: 0.6681 - Val Accuracy: 0.6000 - Best: 0.6000\n",
            "[mlp] Epoch 003 - Loss: 0.6481 - Val Accuracy: 0.5975 - Best: 0.6000\n",
            "[mlp] Epoch 004 - Loss: 0.6310 - Val Accuracy: 0.5850 - Best: 0.6000\n",
            "[mlp] Epoch 005 - Loss: 0.6186 - Val Accuracy: 0.5550 - Best: 0.6000\n",
            "[mlp] Epoch 006 - Loss: 0.6065 - Val Accuracy: 0.5650 - Best: 0.6000\n",
            "[mlp] Epoch 007 - Loss: 0.5945 - Val Accuracy: 0.5775 - Best: 0.6000\n",
            "[mlp] Epoch 008 - Loss: 0.5856 - Val Accuracy: 0.5825 - Best: 0.6000\n",
            "[mlp] Epoch 009 - Loss: 0.5772 - Val Accuracy: 0.5875 - Best: 0.6000\n",
            "[mlp] Epoch 010 - Loss: 0.5677 - Val Accuracy: 0.5875 - Best: 0.6000\n",
            "[mlp] Epoch 011 - Loss: 0.5593 - Val Accuracy: 0.5750 - Best: 0.6000\n",
            "[mlp] Epoch 012 - Loss: 0.5498 - Val Accuracy: 0.5800 - Best: 0.6000\n",
            "[mlp] Epoch 013 - Loss: 0.5417 - Val Accuracy: 0.5750 - Best: 0.6000\n",
            "[mlp] Epoch 014 - Loss: 0.5332 - Val Accuracy: 0.5850 - Best: 0.6000\n",
            "[mlp] Epoch 015 - Loss: 0.5242 - Val Accuracy: 0.5750 - Best: 0.6000\n",
            "[mlp] Epoch 016 - Loss: 0.5143 - Val Accuracy: 0.5825 - Best: 0.6000\n",
            "[mlp] Epoch 017 - Loss: 0.5068 - Val Accuracy: 0.5625 - Best: 0.6000\n",
            "[mlp] Epoch 018 - Loss: 0.4973 - Val Accuracy: 0.5850 - Best: 0.6000\n",
            "[mlp] Epoch 019 - Loss: 0.4908 - Val Accuracy: 0.5800 - Best: 0.6000\n",
            "[mlp] Epoch 020 - Loss: 0.4820 - Val Accuracy: 0.5925 - Best: 0.6000\n"
          ]
        }
      ],
      "source": [
        "#  Submission 11 - Triple Ensemble (CNN+KMeans, CNNOnly, MLP on Clusters)\n",
        "\n",
        "# Normalize KMeans features\n",
        "scaler = StandardScaler()\n",
        "X_cluster = scaler.fit_transform(X_cluster)\n",
        "X_test_cluster = scaler.transform(X_test_cluster)\n",
        "\n",
        "X_cluster_tensor = torch.tensor(X_cluster, dtype=torch.float32)\n",
        "X_test_cluster_tensor = torch.tensor(X_test_cluster, dtype=torch.float32)\n",
        "\n",
        "# Train/Val Split\n",
        "X_seq_train, X_seq_val, X_clust_train, X_clust_val, y_train, y_val = train_test_split(\n",
        "    X_seq_tensor, X_cluster_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dataset Class\n",
        "class DualInputDataset(Dataset):\n",
        "    def __init__(self, seq_tensor, clust_tensor, labels):\n",
        "        self.seq = seq_tensor\n",
        "        self.clust = clust_tensor\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.seq[idx], self.clust[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DualInputDataset(X_seq_train, X_clust_train, y_train)\n",
        "val_dataset = DualInputDataset(X_seq_val, X_clust_val, y_val)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# Models\n",
        "class CNNKMeansFusion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(4, 128, kernel_size=9, padding=4),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=15, padding=7),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(256 + 50, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x_seq, x_clust):\n",
        "        x_cnn = self.cnn(x_seq)\n",
        "        x_concat = torch.cat([x_cnn, x_clust], dim=1)\n",
        "        return self.mlp(x_concat)\n",
        "\n",
        "class CNNOnly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(4, 128, kernel_size=7, padding=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=11, padding=5),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class MLPOnClusters(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(50, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Instantiate models\n",
        "model1 = CNNKMeansFusion()\n",
        "model2 = CNNOnly()\n",
        "model3 = MLPOnClusters()\n",
        "\n",
        "# Loss + Optimizers\n",
        "loss_fn = nn.BCELoss()\n",
        "opt1 = torch.optim.Adam(model1.parameters(), lr=0.002)\n",
        "opt2 = torch.optim.Adam(model2.parameters(), lr=0.003)\n",
        "opt3 = torch.optim.Adam(model3.parameters(), lr=0.001)\n",
        "\n",
        "# --- 5. Training (Simple Loop for each model) ---\n",
        "def train_model(model, optimizer, train_loader, val_loader, mode=\"cnn_only\"):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(20):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xb, xc, yb in train_loader:\n",
        "            if mode == \"cnn_only\":\n",
        "                preds = model(xb).squeeze()\n",
        "            elif mode == \"mlp\":\n",
        "                preds = model(xc).squeeze()\n",
        "            else:\n",
        "                preds = model(xb, xc).squeeze()\n",
        "\n",
        "            loss = loss_fn(preds, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, xc, yb in val_loader:\n",
        "                if mode == \"cnn_only\":\n",
        "                    preds = model(xb).squeeze()\n",
        "                elif mode == \"mlp\":\n",
        "                    preds = model(xc).squeeze()\n",
        "                else:\n",
        "                    preds = model(xb, xc).squeeze()\n",
        "                all_preds.append(preds)\n",
        "                all_targets.append(yb)\n",
        "        val_preds = torch.cat(all_preds)\n",
        "        val_targets = torch.cat(all_targets)\n",
        "        acc = ((val_preds >= 0.5).float() == val_targets).float().mean().item()\n",
        "        print(f\"[{mode}] Epoch {epoch+1:03d} - Loss: {total_loss/len(train_loader):.4f} - Val Accuracy: {acc:.4f} - Best: {max(acc, best_acc):.4f}\")\n",
        "        best_acc = max(acc, best_acc)\n",
        "\n",
        "# Train all 3 models\n",
        "print(\"üîß Training CNN+KMeans model...\")\n",
        "train_model(model1, opt1, train_loader, val_loader, mode=\"cnn_kmeans\")\n",
        "print(\"\\nüîß Training CNNOnly model...\")\n",
        "train_model(model2, opt2, train_loader, val_loader, mode=\"cnn_only\")\n",
        "print(\"\\nüîß Training MLPOnClusters model...\")\n",
        "train_model(model3, opt3, train_loader, val_loader, mode=\"mlp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "WM_lHN0bYc96",
        "outputId": "82c25493-2588-453f-b502-93809fe01ef3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bd61798210a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- 7. Generate predictions (Ensemble 60/40) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpreds1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_cluster_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpreds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_seq_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfinal_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# --- 7. Generate predictions (Ensemble 60/40) ---\n",
        "with torch.no_grad():\n",
        "    preds1 = model1(X_test_seq_tensor, X_test_cluster_tensor).squeeze()\n",
        "    preds2 = model2(X_test_seq_tensor).squeeze()\n",
        "    final_preds = (0.6 * preds1 + 0.4 * preds2 >= 0.5).int().cpu().numpy()\n",
        "\n",
        "# --- 8. Save submission file ---\n",
        "with open(\"submission11.csv\", \"w\") as f:\n",
        "    f.write(\"Id,Bound\\n\")\n",
        "    for i, p in enumerate(final_preds):\n",
        "        f.write(f\"{i},{p}\\n\")\n",
        "\n",
        "print(\"Submission file 'submission.csv' ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKuVGhiMVzGK",
        "outputId": "4c293d9c-a025-4c25-da5a-939a5620064f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 4, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/__init__.py\", line 6, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 433, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n"
          ]
        }
      ],
      "source": [
        "# Submit\n",
        "!kaggle competitions submit -c dna-intro-to-neural-nets-aims-rwanda-2025 -f submission12.csv -m \"Submission 12 - Ensemble (CNN+KMeans + CNN-only avg)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BShFyuZkb9S5"
      },
      "source": [
        "### Other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RoM4ckHe4Li",
        "outputId": "1191a5ff-179d-4d4d-d857-51a808603be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîß Training CNN+KMeans model...\n",
            "[cnn_kmeans] Epoch 01 - Loss: 0.7163 - Val Accuracy: 0.4850 - Best: 0.4850\n",
            "[cnn_kmeans] Epoch 02 - Loss: 0.6503 - Val Accuracy: 0.6600 - Best: 0.6600\n",
            "[cnn_kmeans] Epoch 03 - Loss: 0.5700 - Val Accuracy: 0.5625 - Best: 0.6600\n",
            "[cnn_kmeans] Epoch 04 - Loss: 0.4967 - Val Accuracy: 0.6975 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 05 - Loss: 0.4102 - Val Accuracy: 0.6700 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 06 - Loss: 0.3248 - Val Accuracy: 0.6550 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 07 - Loss: 0.3157 - Val Accuracy: 0.6850 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 08 - Loss: 0.1960 - Val Accuracy: 0.6950 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 09 - Loss: 0.1917 - Val Accuracy: 0.6950 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 10 - Loss: 0.0948 - Val Accuracy: 0.6875 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 11 - Loss: 0.0992 - Val Accuracy: 0.6600 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 12 - Loss: 0.0833 - Val Accuracy: 0.6850 - Best: 0.6975\n",
            "[cnn_kmeans] Epoch 13 - Loss: 0.1039 - Val Accuracy: 0.7000 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 14 - Loss: 0.1728 - Val Accuracy: 0.6850 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 15 - Loss: 0.1322 - Val Accuracy: 0.6850 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 16 - Loss: 0.0781 - Val Accuracy: 0.6800 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 17 - Loss: 0.1033 - Val Accuracy: 0.6950 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 18 - Loss: 0.1000 - Val Accuracy: 0.6925 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 19 - Loss: 0.0791 - Val Accuracy: 0.6875 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 20 - Loss: 0.0650 - Val Accuracy: 0.6950 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 21 - Loss: 0.1364 - Val Accuracy: 0.6800 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 22 - Loss: 0.1183 - Val Accuracy: 0.6600 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 23 - Loss: 0.1001 - Val Accuracy: 0.6725 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 24 - Loss: 0.1292 - Val Accuracy: 0.6600 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 25 - Loss: 0.1050 - Val Accuracy: 0.6700 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 26 - Loss: 0.0865 - Val Accuracy: 0.6825 - Best: 0.7000\n",
            "[cnn_kmeans] Epoch 27 - Loss: 0.0631 - Val Accuracy: 0.7075 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 28 - Loss: 0.0542 - Val Accuracy: 0.6650 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 29 - Loss: 0.0616 - Val Accuracy: 0.6825 - Best: 0.7075\n",
            "[cnn_kmeans] Epoch 30 - Loss: 0.0559 - Val Accuracy: 0.6800 - Best: 0.7075\n",
            "\n",
            "üîß Training CNNOnly model...\n",
            "[cnn_only] Epoch 01 - Loss: 0.6961 - Val Accuracy: 0.6150 - Best: 0.6150\n",
            "[cnn_only] Epoch 02 - Loss: 0.6184 - Val Accuracy: 0.7175 - Best: 0.7175\n",
            "[cnn_only] Epoch 03 - Loss: 0.4965 - Val Accuracy: 0.7150 - Best: 0.7175\n",
            "[cnn_only] Epoch 04 - Loss: 0.3769 - Val Accuracy: 0.6300 - Best: 0.7175\n",
            "[cnn_only] Epoch 05 - Loss: 0.2740 - Val Accuracy: 0.6175 - Best: 0.7175\n",
            "[cnn_only] Epoch 06 - Loss: 0.1914 - Val Accuracy: 0.6725 - Best: 0.7175\n",
            "[cnn_only] Epoch 07 - Loss: 0.0972 - Val Accuracy: 0.6925 - Best: 0.7175\n",
            "[cnn_only] Epoch 08 - Loss: 0.0258 - Val Accuracy: 0.7000 - Best: 0.7175\n",
            "[cnn_only] Epoch 09 - Loss: 0.0064 - Val Accuracy: 0.7025 - Best: 0.7175\n",
            "[cnn_only] Epoch 10 - Loss: 0.0060 - Val Accuracy: 0.6850 - Best: 0.7175\n",
            "[cnn_only] Epoch 11 - Loss: 0.0040 - Val Accuracy: 0.7075 - Best: 0.7175\n",
            "[cnn_only] Epoch 12 - Loss: 0.0177 - Val Accuracy: 0.7050 - Best: 0.7175\n",
            "[cnn_only] Epoch 13 - Loss: 0.0199 - Val Accuracy: 0.7000 - Best: 0.7175\n",
            "[cnn_only] Epoch 14 - Loss: 0.0045 - Val Accuracy: 0.7100 - Best: 0.7175\n",
            "[cnn_only] Epoch 15 - Loss: 0.0016 - Val Accuracy: 0.7125 - Best: 0.7175\n",
            "[cnn_only] Epoch 16 - Loss: 0.0006 - Val Accuracy: 0.7175 - Best: 0.7175\n",
            "[cnn_only] Epoch 17 - Loss: 0.0005 - Val Accuracy: 0.7175 - Best: 0.7175\n",
            "[cnn_only] Epoch 18 - Loss: 0.0004 - Val Accuracy: 0.7125 - Best: 0.7175\n",
            "[cnn_only] Epoch 19 - Loss: 0.0008 - Val Accuracy: 0.7100 - Best: 0.7175\n",
            "[cnn_only] Epoch 20 - Loss: 0.0003 - Val Accuracy: 0.7150 - Best: 0.7175\n",
            "[cnn_only] Epoch 21 - Loss: 0.0003 - Val Accuracy: 0.7100 - Best: 0.7175\n",
            "[cnn_only] Epoch 22 - Loss: 0.0003 - Val Accuracy: 0.7100 - Best: 0.7175\n",
            "[cnn_only] Epoch 23 - Loss: 0.0002 - Val Accuracy: 0.7225 - Best: 0.7225\n",
            "[cnn_only] Epoch 24 - Loss: 0.0002 - Val Accuracy: 0.7250 - Best: 0.7250\n",
            "[cnn_only] Epoch 25 - Loss: 0.0001 - Val Accuracy: 0.7125 - Best: 0.7250\n",
            "[cnn_only] Epoch 26 - Loss: 0.0002 - Val Accuracy: 0.7200 - Best: 0.7250\n",
            "[cnn_only] Epoch 27 - Loss: 0.0001 - Val Accuracy: 0.7200 - Best: 0.7250\n",
            "[cnn_only] Epoch 28 - Loss: 0.0001 - Val Accuracy: 0.7175 - Best: 0.7250\n",
            "[cnn_only] Epoch 29 - Loss: 0.0001 - Val Accuracy: 0.7200 - Best: 0.7250\n",
            "[cnn_only] Epoch 30 - Loss: 0.0001 - Val Accuracy: 0.7100 - Best: 0.7250\n",
            "\n",
            "üîß Training MLPOnClusters model...\n",
            "[mlp] Epoch 01 - Loss: 0.6782 - Val Accuracy: 0.6025 - Best: 0.6025\n",
            "[mlp] Epoch 02 - Loss: 0.6321 - Val Accuracy: 0.5925 - Best: 0.6025\n",
            "[mlp] Epoch 03 - Loss: 0.6016 - Val Accuracy: 0.6050 - Best: 0.6050\n",
            "[mlp] Epoch 04 - Loss: 0.5730 - Val Accuracy: 0.5950 - Best: 0.6050\n",
            "[mlp] Epoch 05 - Loss: 0.5486 - Val Accuracy: 0.5950 - Best: 0.6050\n",
            "[mlp] Epoch 06 - Loss: 0.5283 - Val Accuracy: 0.5875 - Best: 0.6050\n",
            "[mlp] Epoch 07 - Loss: 0.5049 - Val Accuracy: 0.5900 - Best: 0.6050\n",
            "[mlp] Epoch 08 - Loss: 0.4836 - Val Accuracy: 0.5925 - Best: 0.6050\n",
            "[mlp] Epoch 09 - Loss: 0.4628 - Val Accuracy: 0.5850 - Best: 0.6050\n",
            "[mlp] Epoch 10 - Loss: 0.4447 - Val Accuracy: 0.5950 - Best: 0.6050\n",
            "[mlp] Epoch 11 - Loss: 0.4232 - Val Accuracy: 0.6075 - Best: 0.6075\n",
            "[mlp] Epoch 12 - Loss: 0.4023 - Val Accuracy: 0.6200 - Best: 0.6200\n",
            "[mlp] Epoch 13 - Loss: 0.3845 - Val Accuracy: 0.6025 - Best: 0.6200\n",
            "[mlp] Epoch 14 - Loss: 0.3668 - Val Accuracy: 0.6100 - Best: 0.6200\n",
            "[mlp] Epoch 15 - Loss: 0.3464 - Val Accuracy: 0.5950 - Best: 0.6200\n",
            "[mlp] Epoch 16 - Loss: 0.3320 - Val Accuracy: 0.6100 - Best: 0.6200\n",
            "[mlp] Epoch 17 - Loss: 0.3117 - Val Accuracy: 0.6025 - Best: 0.6200\n",
            "[mlp] Epoch 18 - Loss: 0.2990 - Val Accuracy: 0.6025 - Best: 0.6200\n",
            "[mlp] Epoch 19 - Loss: 0.2816 - Val Accuracy: 0.5800 - Best: 0.6200\n",
            "[mlp] Epoch 20 - Loss: 0.2642 - Val Accuracy: 0.6075 - Best: 0.6200\n",
            "[mlp] Epoch 21 - Loss: 0.2506 - Val Accuracy: 0.6075 - Best: 0.6200\n",
            "[mlp] Epoch 22 - Loss: 0.2345 - Val Accuracy: 0.5875 - Best: 0.6200\n",
            "[mlp] Epoch 23 - Loss: 0.2216 - Val Accuracy: 0.6100 - Best: 0.6200\n",
            "[mlp] Epoch 24 - Loss: 0.2081 - Val Accuracy: 0.6125 - Best: 0.6200\n",
            "[mlp] Epoch 25 - Loss: 0.1975 - Val Accuracy: 0.6100 - Best: 0.6200\n",
            "[mlp] Epoch 26 - Loss: 0.1842 - Val Accuracy: 0.6025 - Best: 0.6200\n",
            "[mlp] Epoch 27 - Loss: 0.1756 - Val Accuracy: 0.5925 - Best: 0.6200\n",
            "[mlp] Epoch 28 - Loss: 0.1625 - Val Accuracy: 0.6050 - Best: 0.6200\n",
            "[mlp] Epoch 29 - Loss: 0.1527 - Val Accuracy: 0.5925 - Best: 0.6200\n",
            "[mlp] Epoch 30 - Loss: 0.1441 - Val Accuracy: 0.6100 - Best: 0.6200\n"
          ]
        }
      ],
      "source": [
        "# --- One-hot encoding ---\n",
        "def one_hot_encode_seq(seq, maxlen=101):\n",
        "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "    one_hot = np.zeros((4, maxlen), dtype=np.float32)\n",
        "    for i, char in enumerate(seq):\n",
        "        if char in mapping:\n",
        "            one_hot[mapping[char], i] = 1.0\n",
        "    return one_hot\n",
        "\n",
        "X_seq = np.stack([one_hot_encode_seq(seq) for seq in Xtr[\"seq\"]])\n",
        "X_test_seq = np.stack([one_hot_encode_seq(seq) for seq in Xte[\"seq\"]])\n",
        "\n",
        "X_seq_tensor = torch.tensor(X_seq, dtype=torch.float32)\n",
        "X_test_seq_tensor = torch.tensor(X_test_seq, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(Ytr[\"Bound\"].values, dtype=torch.float32)\n",
        "\n",
        "X_cluster = StandardScaler().fit_transform(Xtr_mat.values)\n",
        "X_test_cluster = StandardScaler().fit_transform(Xte_mat.values)\n",
        "X_cluster_tensor = torch.tensor(X_cluster, dtype=torch.float32)\n",
        "X_test_cluster_tensor = torch.tensor(X_test_cluster, dtype=torch.float32)\n",
        "\n",
        "# --- Data preparation ---\n",
        "X_seq_train, X_seq_val, X_clust_train, X_clust_val, y_train, y_val = train_test_split(\n",
        "    X_seq_tensor, X_cluster_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "class DualInputDataset(Dataset):\n",
        "    def __init__(self, seq_tensor, clust_tensor, labels):\n",
        "        self.seq = seq_tensor\n",
        "        self.clust = clust_tensor\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.seq[idx], self.clust[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DualInputDataset(X_seq_train, X_clust_train, y_train)\n",
        "val_dataset = DualInputDataset(X_seq_val, X_clust_val, y_val)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# --- Models ---\n",
        "class CNNKMeansFusion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(4, 128, kernel_size=9, padding=4),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=15, padding=7),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(256 + 100, 256),  # 256 from CNN, 100 from KMeans\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x_seq, x_clust):\n",
        "        x_cnn = self.cnn(x_seq)\n",
        "        x_concat = torch.cat([x_cnn, x_clust], dim=1)\n",
        "        return self.mlp(x_concat)\n",
        "\n",
        "class CNNOnly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(4, 128, kernel_size=7, padding=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, kernel_size=11, padding=5),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveMaxPool1d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class MLPOnClusters(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(100, 64),  # üîß fix here\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Instantiate models\n",
        "model1 = CNNKMeansFusion()\n",
        "model2 = CNNOnly()\n",
        "model3 = MLPOnClusters()\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "opt1 = torch.optim.Adam(model1.parameters(), lr=0.002)\n",
        "opt2 = torch.optim.Adam(model2.parameters(), lr=0.003)\n",
        "opt3 = torch.optim.Adam(model3.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, optimizer, train_loader, val_loader, mode=\"cnn_only\"):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(30):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xb, xc, yb in train_loader:\n",
        "            if mode == \"cnn_only\":\n",
        "                preds = model(xb).squeeze()\n",
        "            elif mode == \"mlp\":\n",
        "                preds = model(xc).squeeze()\n",
        "            else:\n",
        "                preds = model(xb, xc).squeeze()\n",
        "\n",
        "            loss = loss_fn(preds, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, xc, yb in val_loader:\n",
        "                if mode == \"cnn_only\":\n",
        "                    preds = model(xb).squeeze()\n",
        "                elif mode == \"mlp\":\n",
        "                    preds = model(xc).squeeze()\n",
        "                else:\n",
        "                    preds = model(xb, xc).squeeze()\n",
        "                all_preds.append(preds)\n",
        "                all_targets.append(yb)\n",
        "        val_preds = torch.cat(all_preds)\n",
        "        val_targets = torch.cat(all_targets)\n",
        "        acc = ((val_preds >= 0.5).float() == val_targets).float().mean().item()\n",
        "        print(f\"[{mode}] Epoch {epoch+1:02d} - Loss: {total_loss/len(train_loader):.4f} - Val Accuracy: {acc:.4f} - Best: {max(acc, best_acc):.4f}\")\n",
        "        best_acc = max(acc, best_acc)\n",
        "\n",
        "# --- Train all models ---\n",
        "print(\"\\nüîß Training CNN+KMeans model...\")\n",
        "train_model(model1, opt1, train_loader, val_loader, mode=\"cnn_kmeans\")\n",
        "print(\"\\nüîß Training CNNOnly model...\")\n",
        "train_model(model2, opt2, train_loader, val_loader, mode=\"cnn_only\")\n",
        "print(\"\\nüîß Training MLPOnClusters model...\")\n",
        "train_model(model3, opt3, train_loader, val_loader, mode=\"mlp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrq8dhHRf3_9",
        "outputId": "b16802f0-b86b-44c2-903e-206dc5098b17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file 'sub10.csv' generated successfully.\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions from CNN+KMeans and CNNOnly\n",
        "with torch.no_grad():\n",
        "    preds1 = model1(X_test_seq_tensor, X_test_cluster_tensor).squeeze()\n",
        "    preds2 = model2(X_test_seq_tensor).squeeze()\n",
        "\n",
        "    alpha = 0.27\n",
        "    final_probs = (alpha * preds1 + (1 - alpha) * preds2).cpu().numpy()\n",
        "    final_preds = (final_probs >= 0.5).astype(int)\n",
        "\n",
        "#  savesubmission file\n",
        "submission_name = \"sub10.csv\"\n",
        "with open(submission_name, \"w\") as f:\n",
        "    f.write(\"Id,Bound\\n\")\n",
        "    for i, p in enumerate(final_preds):\n",
        "        f.write(f\"{i},{p}\\n\")\n",
        "\n",
        "print(f\"Submission file '{submission_name}' generated successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gLz3xOfYLvcz",
        "outputId": "38347bd2-2caa-4a23-f2ca-e931dbe57379"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_098332f2-95df-44d6-b847-4e214f1f5371\", \"sub10.csv\", 5899)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(submission_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKpy0LSPspOF",
        "outputId": "5e37c3e4-e7dc-4278-9f41-e66923333913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.5.8)\n",
            "100% 5.76k/5.76k [00:00<00:00, 31.0kB/s]\n",
            "400 - Bad Request\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c dna-intro-to-neural-nets-aims-rwanda-2025 -f submission_cnn_kmeans_cnnonly.csv -m \"Submission 15 - Weighted ensemble (0.75 CNNOnly, 0.15 CNN+KMeans, 0.10 MLP)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo9V7cmTzQnt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
